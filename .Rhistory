setwd('/home/minh/Dropbox (Optimus)/rubio/contact/nv/read-2015-09-17/returns/')
list.files()
dataa<-data.frame()
for (i in 4:7){
newdf<-read.csv(list.files()[i], na = '')
dataa<-rbind(dataa, newdf)
}
dataa$version <- "A"
datab<-data.frame()
for (i in 8:11){
newdf<-read.csv(list.files()[i], na = '')
datab<-rbind(datab, newdf)
}
datab$version <- "B"
names(dataa);names(datab)
dataa<- dataa[,c("lalvoterid","cohort","ques1","ques2","ques3","ques4","ques5","ques6","ques7","ques8","version")]
datab<- datab[,c("lalvoterid","cohort", "ques1","ques2","ques3","ques4","ques5","ques6","ques7","ques8","version")]
data <- rbind(dataa, datab)
new<-read.csv('../../read-2015-09-22/post-analysis/nv-fls-combo.csv')
new <- new[,c("lalvoterid","cohort", "ques1","ques2","ques3","ques4","ques5","ques6","ques7","ques8","Target")]
names(new)[ncol(new)] <- 'version'
new <- new[which(is.na(new$ques2)==FALSE),]
data<-rbind(data, new)
head(data)
names(data)
data$proven_finv_soco_type <- ifelse(data$ques3 == 1, 1, ifelse(data$ques3 == 2 | data$ques3 == 3, 0, NA))
data$proven_executive_type <- ifelse(data$ques3 == 2, 1, ifelse(data$ques3 == 1 | data$ques3 == 3, 0, NA))
data$outsider_type <- ifelse(data$ques3 == 3, 1, ifelse(data$ques3 == 1 | data$ques3 == 2, 0, NA))
data$ballotest_marco_support <- ifelse(data$ques4 == 4, 1,ifelse(is.na(data$ques4), NA, 0))
data$ballottest_establishment_support <-ifelse(data$ques4 == 1 | data$ques4 == 2 | data$ques4 == 4, 1, ifelse(is.na(data$ques4), NA, 0))
data$marco_strong_fav <- ifelse(data$ques5 == 2 , 1,  ifelse(is.na(data$ques5), NA, 0))
data$maco_strong_and_somewhat_fav <- ifelse(data$ques5 == 2 | data$ques5 == 3, 1, ifelse(is.na(data$ques5), NA, 0))
data$marco_favor_or_second_fav <- ifelse(data$ques6 == 2 | data$ques6 == 3 ,1,  ifelse(is.na(data$ques6), NA, 0))
data$macro_strong_and_second_or_seesupport <- ifelse(data$ques6 == 2 | data$ques6 == 3 | data$ques6 == 4, 1,  ifelse(is.na(data$ques6), NA, 0))
data$dinvrepancy_low_info_changevote = ifelse(data$version == "A" & data$ques8 == 1, 1,  ifelse(is.na(data$ques8), NA, 0))
data$dinvrepancy_low_info_changevote_or_ser_cons =ifelse(data$version == "A" & (data$ques8 == 1 | data$ques8 == 2), 1,  ifelse(is.na(data$ques8), NA, 0))
data$dinvrepancy_low_info_changevote_or_ser_cons_or_learnmore = ifelse(data$version == "A" & (data$ques8 == 1 | data$ques8 == 3), 1,  ifelse(is.na(data$ques8), NA, 0))
data$dinvrepancy_high_info_changevote = ifelse(data$version == "B" & data$ques8 == 1, 1,  ifelse(is.na(data$ques8), NA, 0))
data$dinvrepancy_high_info_changevote_or_ser_cons =ifelse(data$version == "B" & (data$ques8 == 1 | data$ques8 == 2), 1,  ifelse(is.na(data$ques8), NA, 0))
data$dinvrepancy_high_info_changevote_or_ser_cons_or_learnmore = ifelse(data$version == "B" & (data$ques8 == 1 | data$ques8 == 3), 1,  ifelse(is.na(data$ques8), NA, 0))
table(data$proven_executive_type)
table(data$marco_strong_fav)
table(data$ballotest_marco_support)
table(data$macro_strong_and_second_or_seesupport)
table(data$dinvrepancy_low_info_changevote_or_ser_cons_or_learnmore)
table(data$dinvrepancy_high_info_changevote_or_ser_cons)
names(data)
models <- data[,c(1,12:26)]
length(unique(data$lalvoterid))
data <- data[which(is.na(data$lalvoterid)==FALSE),]
data2 <- data[!duplicated(data),]
length(unique(data2$lalvoterid))
data2 <- data[!duplicated(data$lalvoterid),]
models <- models[!duplicated(moels$lalvoterid),]
models <- models[!duplicated(models$lalvoterid),]
head(models)
write.csv(models, "../../../../data/nv_2016pc/models/model-data/models-2015-10-06.csv", na="", row.names=F)
table(data$proven_executive_type)
table(data$marco_strong_fav)
table(data$ballotest_marco_support)
table(data$macro_strong_and_second_or_seesupport)
table(data$dinvrepancy_low_info_changevote_or_ser_cons_or_learnmore)
table(data$dinvrepancy_high_info_changevote_or_ser_cons)
setwd("~/mrp/")
library(caret)
setwd("~/portfolio/mrp/")
load("data.RData")
load("data.RData")
list.files()
load("data.RData")
ageGroups <- as.data.frame(cut(tmpData$demAgeFull, breaks = c(0,18,35,55,Inf), labels = c("under 18","18-35","35-55", "55+")))
names(ageGroups) <- "ageGroups"
eduGroups <- as.data.frame(cut(tmpData$demEduFull, breaks = c(0,3,7,9), labels = c("Up to HS", "Up to College", "PostGraduate")))
names(eduGroups) <- "eduGroups"
#cleaning up dataset
dataPrep <- tmpData[,c("nr1","demGender","demRace","demHisp")]
dataPrep <- cbind(dataPrep, ageGroups, eduGroups)
#explicitly typecast numeric into factor variables
names(dataPrep)
for (i in 2:5){
dataPrep[,i] <- as.factor(dataPrep[,i])
}
head(dataPrep)
dummies <- dummyVars(nr1 ~ ., data= dataPrep)
data <- as.data.frame(predict(dummies, newdata = dataPrep))
data <- cbind(data, tmpData$demState)
names(data) <- c("male","female","native","asian","black","white","other.race","hisp","notHisp","dem","gop","other.par",
"under18","age18.35","age35.55","age55plus", "hs","college","postgraduate","demState")
names(data) <- c("male","female","native","asian","black","white","other.race","hisp","notHisp",
"under18","age18.35","age35.55","age55plus", "hs","college","postgraduate","demState")
data$newengland <- ifelse(data$demState %in% c(7, 20, 22, 30, 40, 46), 1,0)
data$midatlantic <- ifelse(data$demState %in% c(31, 33, 39),1,0)
data$eastcentral <- ifelse(data$demState %in% c(16, 14, 23, 36, 50),1,0)
data$westcentral <- ifelse(data$demState %in% c(16, 17, 24, 26, 28, 35, 42),1,0)
data$southatlantic <- ifelse(data$demState %in% c(8, 9, 10, 11, 21, 34, 41, 47, 49),1,0)
data$southeast <- ifelse(data$demState %in% c(1,18, 25, 43), 1, 0)
data$southwest <- ifelse(data$demState %in% c(2, 19, 37, 44), 1, 0)
data$moutain <-  ifelse(data$demState %in% c(3, 6, 13, 32, 27,45, 51), 1, 0)
data$pacific <- ifelse(data$demState %in% c(2,5, 12, 38, 48), 1, 0)
names(data)
data <- data[,-grep("^demState",names(data))]
#creating columns where we are trying to measure predict
right <- as.data.frame(ifelse(tmpData$nr1 == 1, 1, 0))
names(right) <- "right"
data <- cbind(right, data)
data$right <- as.factor(data$right)
levels(data$right) <- c("No", "Yes")
#create training and test set
split <- createDataPartition(data$right, p=.8)[[1]]
set.seed(938479382)
split <- createDataPartition(data$right, p=.8)[[1]]
train<-data[split,]
test<-data[-split,]
#creating controller for training
control <- trainControl(method = "cv",
number = 10,
savePredictions = TRUE,
classProbs = TRUE,
summaryFunction = twoClassSummary)
#creating results table
results <- as.data.frame(test$right)
names(results)[1] <- 'obs'
#Running random forest
require(randomForest)
tuningGrid <- data.frame(.mtry = floor(seq(1 , ncol(train) , length = 6)))
rf_tune <- train(right ~ . ,
data=train,
method = "rf" ,
metric = "ROC",
tuneGrid = tuningGrid,
trControl = control)
rf_tune
results$rf <- predict.train(rf_tune, newdata=test, type = 'prob')
#Good ol' logistic regression
logit_tune <- train(right ~.,
method = 'glm',
data = train,
trControl = control)
logit_tune
results$logit <- predict(logit_tune, newdata = test, type = 'prob')
#Classification and Regression Tree, because why not.
require(rpart)
cart_tune = train(right ~ . ,
data = train ,
method = "rpart" ,
metric = "ROC" ,
tuneLength = 25 ,
trControl = control)
cart_tune
results$cart <- predict(cart_tune, newdata = test, type = 'prob')
#Boosting because I heard it's really good machine learning algorithm (commented because it takes too long to iterate)
# require(gbm)
# tuningGrid <- expand.grid(.n.trees = seq(200,1000,by = 200),
#                           .interaction.depth = seq(1,7, by = 3 ),
#                           .shrinkage = seq(.001, .01, by = .001),
#                           .n.minobsinnode = seq(20,60, by = 20))
#
# gbm_tune = train(right ~ . ,
#                  data = train ,
#                  method = "gbm" ,
#                  metric = "ROC" ,
#                  tuneGrid = tuningGrid,
#                  trControl = control)
# gbm_tune
# results$gbm <- predict(gbm_tune, newdata = test)
#Alot of talk has been on the accuracy of neural network algorithm, having a go at it here.
require(nnet)
tuningGrid<-expand.grid(.size = 1:5, .decay = c(0, 2, by = .5))
nnet_tune <- train(right ~ .,
data = train,
method = "nnet",
metric = "ROC",
tuneGrid = tuningGrid,
trControl = control)
nnet_tune
results$nnet <- predict(nnet_tune, newdata = test, type = 'prob')
eval <- as.data.frame(results$obs)
for (i in 2:ncol(results)){
sub <- as.data.frame(results[,i][2])
eval <- cbind(eval,sub)
}
eval <- as.data.frame(eval)
names(eval) <- names(results)
eval$obs <- ifelse(eval$obs == 'Yes', 1, 0)
#model evaluation
require(scoring)
mean(brierscore(obs ~ rf, data = eval))
mean(brierscore(obs ~ logit, data = eval))
mean(brierscore(obs ~ cart, data = eval))
mean(brierscore(obs ~ nnet, data = eval)) #winner
install.packages("scoring")
require(scoring)
mean(brierscore(obs ~ rf, data = eval))
mean(brierscore(obs ~ logit, data = eval))
mean(brierscore(obs ~ cart, data = eval))
mean(brierscore(obs ~ nnet, data = eval))
# applying models
data$prediction <- predict(nnet_tune, newdata = data, type = 'prob')
data <- cbind(data, tmpData$demState)
names(data)[ncol(data)] <- 'demState'
tapply(data$prediction[[2]], data$demState, mean)
post <- rbind(data, dataPrep)
post <- cbind(data, dataPrep)
head(post)
table(post$ageGroups)
table(post$eduGroups)
post$race <- factor(post$demRace)
levels(post$race) <- c('White', 'Black', 'Native', 'Native', 'Native', 'Asian', 'Asian', 'Other', 'Other')
post$gender <- ifelse(post$demGender == 1, "Male", "Female")
post$hisp <-ifelse(post$demHisp == 1, "Hisp", "Not Hisp")
census <- read.csv('census/post-strat.csv')
head(census)
post$state <- factor(post$demState)
table(post$state)
levels(post$state) <- c(1,2,4,5,6,8,9,10,11,12,13,15,
16,17,18,19,20,21,22,23,24,25,
26,27,28,29,30,31,32,33,24,25,
36,37,38,39,40,41,42,44,45,46,
47,48,49,50,51,53,54,55,56,72)
names(post)
census <- rbind(data.table::fread('census/ss13pusa.csv', select = c('ST','AGEP','RAC1P','SCHL','HISP'), data.table = FALSE),
data.table::fread('census/ss13pusb.csv', select = c('ST','AGEP','RAC1P','SCHL','HISP'), data.table = FALSE))
census <- rbind(data.table::fread('census/ss13pusa.csv', select = c('ST','AGEP','RAC1P','SCHL','HISP'), data.table = FALSE),
data.table::fread('census/ss13pusb.csv', select = c('ST','AGEP','RAC1P','SCHL','HISP'), data.table = FALSE))
census$age <- cut(census$AGEP, breaks = c(-Inf,18,35,55,Inf), labels = c("under 18","18-35","35-55", "55+"))
census$education <- cut(census$SCHL, breaks = c(0,16, 21, Inf), labels = c('Up to HS', 'Up to College', 'Postgraduate'))
census$race <- factor(census$RAC1P)
levels(census$race) <- c('White', 'Black', 'Native', 'Native', 'Native', 'Asian', 'Asian', 'Other', 'Other')
census$hisp <- ifelse(census$HISP == 1, "Hisp", "Not Hisp")
#creating cohort levels to get proportions
census$cohort <- paste(census$ST, census$gender, census$age, census$education, census$race, census$hisp, sep=',')
#custom function to grab proportions of each cohort by state
porpFunct <- function(x) {prop.table(table(x))}
proportions <- tapply(census$cohort, census$ST, porpFunct)
proportions <- do.call(rbind, lapply(test, data.frame))
write.csv(proportions, 'census/post-strat.csv', row.names=F)
post$cohort <- paste(post$state, post$gender, post$ageGroups, census$eduGroups, census$race, census$hisp, sep=',')
post$cohort <- paste(post$state, post$gender, post$ageGroups, post$eduGroups, post$race, post$hisp, sep=',')
head(post$cohort)
census <- read.csv('census/post-strat.csv')
head(census$cohort)
head(census$cohort)
View(census)
head(proportions)
census <- rbind(data.table::fread('census/ss13pusa.csv', select = c('ST','AGEP','RAC1P','SCHL','HISP'), data.table = FALSE),
data.table::fread('census/ss13pusb.csv', select = c('ST','AGEP','RAC1P','SCHL','HISP'), data.table = FALSE))
census$age <- cut(census$AGEP, breaks = c(-Inf,18,35,55,Inf), labels = c("under 18","18-35","35-55", "55+"))
census$education <- cut(census$SCHL, breaks = c(0,16, 21, Inf), labels = c('Up to HS', 'Up to College', 'Postgraduate'))
census$race <- factor(census$RAC1P)
levels(census$race) <- c('White', 'Black', 'Native', 'Native', 'Native', 'Asian', 'Asian', 'Other', 'Other')
census$hisp <- ifelse(census$HISP == 1, "Hisp", "Not Hisp")
#creating cohort levels to get proportions
census$cohort <- paste(census$ST, census$gender, census$age, census$education, census$race, census$hisp, sep=',')
#custom function to grab proportions of each cohort by state
porpFunct <- function(x) {prop.table(table(x))}
proportions <- tapply(census$cohort, census$ST, porpFunct)
proportions <- do.call(rbind, lapply(test, data.frame))
head(proportions)
head(census$cohort)
census <- rbind(data.table::fread('census/ss13pusa.csv', select = c('ST','SEX','AGEP','RAC1P','SCHL','HISP'), data.table = FALSE),
data.table::fread('census/ss13pusb.csv', select = c('ST','SEX', 'AGEP','RAC1P','SCHL','HISP'), data.table = FALSE))
table(census$SEX)
census$gender <- ifelse(census$SEX == 1, "Male", "Female")
census$age <- cut(census$AGEP, breaks = c(-Inf,18,35,55,Inf), labels = c("under 18","18-35","35-55", "55+"))
census$education <- cut(census$SCHL, breaks = c(0,16, 21, Inf), labels = c('Up to HS', 'Up to College', 'Postgraduate'))
census$race <- factor(census$RAC1P)
levels(census$race) <- c('White', 'Black', 'Native', 'Native', 'Native', 'Asian', 'Asian', 'Other', 'Other')
census$hisp <- ifelse(census$HISP == 1, "Hisp", "Not Hisp")
#creating cohort levels to get proportions
census$cohort <- paste(census$ST, census$gender, census$age, census$education, census$race, census$hisp, sep=',')
head(census$cohort)
porpFunct <- function(x) {prop.table(table(x))}
proportions <- tapply(census$cohort, census$ST, porpFunct)
proportions <- do.call(rbind, lapply(test, data.frame))
head(proportions)
head(census$cohort)
porpFunct <- function(x) {prop.table(table(x))}
proportions <- tapply(census$cohort, census$ST, porpFunct)
proportions[1]
lapply(proportions[1],sum)
proportions <- do.call(rbind, lapply(proportions, data.frame))
head(proportions)
options(scipen=9999)
proportions <- tapply(census$cohort, census$ST, porpFunct)
proportions <- do.call(rbind, lapply(proportions, data.frame))
head(proportions)
write.csv(proportions, 'census/post-strat.csv', row.names=F)
census <- read.csv('census/post-strat.csv')
head(census$cohort)
head(census)
names(proportions) <- c("cohort","weights")
write.csv(proportions, 'census/post-strat.csv', row.names=F)
census <- read.csv('census/post-strat.csv')
head(census)
post <- merge(post, census, by = 'cohort', all.x = T)
head(post)
census <- rbind(data.table::fread('census/ss13pusa.csv', select = c('ST','SEX','AGEP','RAC1P','SCHL','HISP'), data.table = FALSE),
data.table::fread('census/ss13pusb.csv', select = c('ST','SEX', 'AGEP','RAC1P','SCHL','HISP'), data.table = FALSE))
#refactoring variables to match modeling methods
census$gender <- ifelse(census$SEX == 1, "Male", "Female")
census$age <- cut(census$AGEP, breaks = c(-Inf,18,35,55,Inf), labels = c("under 18","18-35","35-55", "55+"))
census$education <- cut(census$SCHL, breaks = c(0,16, 21, Inf), labels = c('Up to HS', 'Up to College', 'Postgraduate'))
census$race <- factor(census$RAC1P)
levels(census$race) <- c('White', 'Black', 'Native', 'Native', 'Native', 'Asian', 'Asian', 'Other', 'Other')
census$hisp <- ifelse(census$HISP == 1, "Hisp", "Not Hisp")
#creating cohort levels to get proportions
census$cohort <- paste(census$ST, census$gender, census$age, census$education, census$race, census$hisp, sep=',')
head(census$cohort)
#custom function to grab proportions of each cohort by state
options(scipen=9999)
porpFunct <- function(x) {prop.table(table(x))}
proportions <- tapply(census$cohort, census$ST, porpFunct)
proportions <- do.call(rbind, lapply(proportions, data.frame))
names(proportions) <- c("cohort","weights")
write.csv(proportions, 'census/post-strat.csv', row.names=F)
census <- read.csv('census/post-strat.csv')
#post-stratification
post <- merge(post, census, by = 'cohort', all.x = T)
head(post)
table(is.na(post$census))
census <- rbind(data.table::fread('census/ss13pusa.csv', select = c('ST','SEX','AGEP','RAC1P','SCHL','HISP'), data.table = FALSE),
data.table::fread('census/ss13pusb.csv', select = c('ST','SEX', 'AGEP','RAC1P','SCHL','HISP'), data.table = FALSE))
#refactoring variables to match modeling methods
census$gender <- ifelse(census$SEX == 1, "Male", "Female")
census$age <- cut(census$AGEP, breaks = c(-Inf,18,35,55,Inf), labels = c("under 18","18-35","35-55", "55+"))
census$education <- cut(census$SCHL, breaks = c(0,16, 21, Inf), labels = c('Up to HS', 'Up to College', 'PostGraduate'))
census$race <- factor(census$RAC1P)
levels(census$race) <- c('White', 'Black', 'Native', 'Native', 'Native', 'Asian', 'Asian', 'Other', 'Other')
census$hisp <- ifelse(census$HISP == 1, "Hisp", "Not Hisp")
#creating cohort levels to get proportions
census$cohort <- paste(census$ST, census$gender, census$age, census$education, census$race, census$hisp, sep=',')
head(census$cohort)
#custom function to grab proportions of each cohort by state
options(scipen=9999)
porpFunct <- function(x) {prop.table(table(x))}
proportions <- tapply(census$cohort, census$ST, porpFunct)
proportions <- do.call(rbind, lapply(proportions, data.frame))
names(proportions) <- c("cohort","weights")
write.csv(proportions, 'census/post-strat.csv', row.names=F)
census <- read.csv('census/post-strat.csv')
post <- merge(post, census, by = 'cohort', all.x = T)
head(post)
table(census$cohort)
table(data$ageGroups)
table(data$ageGroups)
table(data$ageGroup)
table(post$ageGroups)
census <- rbind(data.table::fread('census/ss13pusa.csv', select = c('ST','SEX','AGEP','RAC1P','SCHL','HISP'), data.table = FALSE),
data.table::fread('census/ss13pusb.csv', select = c('ST','SEX', 'AGEP','RAC1P','SCHL','HISP'), data.table = FALSE))
#refactoring variables to match modeling methods
census$gender <- ifelse(census$SEX == 1, "Male", "Female")
census$age <- cut(census$AGEP, breaks = c(-Inf,18,35,55,Inf), labels = c("under 18","18-35","35-55", "55+"))
census$education <- cut(census$SCHL, breaks = c(0,16, 21, Inf), labels = c('Up to HS', 'Up to College', 'PostGraduate'))
census$race <- factor(census$RAC1P)
levels(census$race) <- c('White', 'Black', 'Native', 'Native', 'Native', 'Asian', 'Asian', 'Other', 'Other')
census$hisp <- ifelse(census$HISP == 1, "Hisp", "Not Hisp")
table(census$age)
table(census$race)
table(post$race)
table(post$eduGroups)
table(census$education)
head(post)
names(post)
post <- post[,1:38]
head(post)
post$race <- factor(post$demRace)
table(post$race)
levels(post$race) <- c('Native', 'Asian', 'Black', 'White', 'Other')
post$gender <- ifelse(post$demGender == 1, "Male", "Female")
post$hisp <-ifelse(post$demHisp == 1, "Hisp", "Not Hisp")
post$state <- factor(post$demState)
levels(post$state) <- c(1,2,4,5,6,8,9,10,11,12,13,15,
16,17,18,19,20,21,22,23,24,25,
26,27,28,29,30,31,32,33,24,25,
36,37,38,39,40,41,42,44,45,46,
47,48,49,50,51,53,54,55,56,72)
post$cohort <- paste(post$state, post$gender, post$ageGroups, post$eduGroups, post$race, post$hisp, sep=',')
head(post$cohort)
census <- read.csv('census/post-strat.csv')
#post-stratification
post <- merge(post, census, by = 'cohort', all.x = T)
head(post)
table(is.na(post$census))
table(is.na(post$cohort))
table(is.na(post$weights))
missing <- post[which(is.na(post$weights)==TRUE),]
head(missing)
post$weight[is.na(post$weights)] <- mean(post$weight, na.rm = T)
data$prediction <- predict(nnet_tune, newdata = data, type = 'prob')[2]
head(post)
head(post$prediction[2])
post$weights[is.na(post$weights)] <- mean(post$weight, na.rm = T)
post$weights[is.na(post$weights)] <- mean(post$weights, na.rm = T)
post$finalScore <- post$prediction[2] * post$weights
tapply(post$finalScore, post$state, sum)
names(post)
head(state)
head(post$state)
tapply(post$finalScore, post$state, sum)
table(is.na(post$finalScore))
table(is.na(post$state))
head(post$finalScore)
head(post$finalScore)[1]
head(post$finalScore)[2]
tapply(post$finalScore[1], post$state, sum)
head(data$prediction)
post <- cbind(data, dataPrep)
post$race <- factor(post$demRace)
levels(post$race) <- c('Native', 'Asian', 'Black', 'White', 'Other')
post$gender <- ifelse(post$demGender == 1, "Male", "Female")
post$hisp <-ifelse(post$demHisp == 1, "Hisp", "Not Hisp")
post$state <- factor(post$demState)
levels(post$state) <- c(1,2,4,5,6,8,9,10,11,12,13,15,
16,17,18,19,20,21,22,23,24,25,
26,27,28,29,30,31,32,33,24,25,
36,37,38,39,40,41,42,44,45,46,
47,48,49,50,51,53,54,55,56,72)
post$cohort <- paste(post$state, post$gender, post$ageGroups, post$eduGroups, post$race, post$hisp, sep=',')
census <- read.csv('census/post-strat.csv')
#post-stratification
names(post)
post <- merge(post, census, by = 'cohort', all.x = T)
table(is.na(post$weights))
tapply(post$weights, post$state, mean)
tapply(post$weights, post$state, function(x) mean(x, na.rm = T))
means <- as.data.frame(tapply(post$weights, post$state, function(x) mean(x, na.rm = T)))
head(means)
names(means) <- "means"
table(is.na(post$weights))
post$weights[is.na(post$weights)] <- merge(post, means, by.x = 'cohort', by.y = 0, all.x =T)
match <- match(post$state, row.names(means))
match
match <- match(means$means, post$state)
match
match <- match(means$means, row.names(means))
match
match <- merge(post, means, by.x = 'state', by.y = 0)
head(match)
post[which(is.na(post$weights)),"weights"] <- match[which(is.na(match$weights)), 'means']
table(is.na(post$weights))
names(post)
post$finalScore <- post$prediction * post$weights
View(post)
post <- cbind(data, dataPrep)
post$race <- factor(post$demRace)
levels(post$race) <- c('Native', 'Asian', 'Black', 'White', 'Other')
post$gender <- ifelse(post$demGender == 1, "Male", "Female")
post$hisp <-ifelse(post$demHisp == 1, "Hisp", "Not Hisp")
post$state <- factor(post$demState)
levels(post$state) <- c(1,2,4,5,6,8,9,10,11,12,13,15,
16,17,18,19,20,21,22,23,24,25,
26,27,28,29,30,31,32,33,24,25,
36,37,38,39,40,41,42,44,45,46,
47,48,49,50,51,53,54,55,56,72)
post$cohort <- paste(post$state, post$gender, post$ageGroups, post$eduGroups, post$race, post$hisp, sep=',')
census <- read.csv('census/post-strat.csv')
#post-stratification
post <- merge(post, census, by = 'cohort', all.x = T)
table(is.na(post$weights)) #noticed some weights are missing because the cohorts are not represented
# created a table of average weights to impute into missing values
means <- as.data.frame(tapply(post$weights, post$state, function(x) mean(x, na.rm = T)))
names(means) <- "means"
match <- merge(post, means, by.x = 'state', by.y = 0)
View(match)
match[which(is.na(match$weights)), 'means']
post$weights[which(is.na(post$weights))] <- match[which(is.na(match$weights)), 'means']
View(post)
post$finalScore <- post$prediction * post$weights
tapply(post$finalScore[1], post$state, sum)
tapply(post$finalScore, post$state, sum)
names(post)
head(post)
tapply(post$Yes, post$state, sum)
names(post)
tapply(post[,ncol(post)], post$state, sum)
names(post)
head(post)
?taply
?tapply
class(post$finalScore)
head(post$finalScore)
head(post$finalScore)[2]
head(post$finalScore)[1]
as.list((post$finalScore))
head(post$predictions)[1]
head(post$prediction)[1]
head(post$prediction)
head(post$prediction)[1]
head(post$prediction)[[1]]
as.data.frame((post$prediction)[[1]])
post$finalScore <- post$prediction[[1]] * post$weights
tapply(post$finalScore, post$state, sum)
tapply(post$finalScore, post$state, function(x) sum*100)
tapply(post$finalScore, post$state, function(x) sum(x)*100)
